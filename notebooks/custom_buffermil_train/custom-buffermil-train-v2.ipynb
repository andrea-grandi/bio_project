{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-27T09:51:34.259576Z",
     "iopub.status.busy": "2025-01-27T09:51:34.259152Z",
     "iopub.status.idle": "2025-01-27T09:52:06.135595Z",
     "shell.execute_reply": "2025-01-27T09:52:06.134440Z",
     "shell.execute_reply.started": "2025-01-27T09:51:34.259536Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.10)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.9.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.12.14)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch-geometric) (2024.2.0)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.6.1\n",
      "Collecting nystrom-attention\n",
      "  Downloading nystrom_attention-0.0.12-py3-none-any.whl.metadata (657 bytes)\n",
      "Requirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from nystrom-attention) (0.8.0)\n",
      "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from nystrom-attention) (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->nystrom-attention) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->nystrom-attention) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->nystrom-attention) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->nystrom-attention) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->nystrom-attention) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->nystrom-attention) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0->nystrom-attention) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->nystrom-attention) (3.0.2)\n",
      "Downloading nystrom_attention-0.0.12-py3-none-any.whl (4.6 kB)\n",
      "Installing collected packages: nystrom-attention\n",
      "Successfully installed nystrom-attention-0.0.12\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.12.0->tensorboard) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.12.0->tensorboard) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\n",
      "Cloning into 'bio_project'...\n",
      "remote: Enumerating objects: 8461, done.\u001b[K\n",
      "remote: Counting objects: 100% (374/374), done.\u001b[K\n",
      "remote: Compressing objects: 100% (224/224), done.\u001b[K\n",
      "remote: Total 8461 (delta 157), reused 320 (delta 125), pack-reused 8087 (from 1)\u001b[K\n",
      "Receiving objects: 100% (8461/8461), 588.01 MiB | 46.88 MiB/s, done.\n",
      "Resolving deltas: 100% (825/825), done.\n",
      "Updating files: 100% (2379/2379), done.\n"
     ]
    }
   ],
   "source": [
    "# @title Prepare Environment\n",
    "import torch\n",
    "import os\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "#!pip install torch-scatter\n",
    "!pip install torch-geometric\n",
    "!pip install nystrom-attention\n",
    "!pip install tensorboard\n",
    "!git clone https://github.com/andrea-grandi/bio_project\n",
    "!cd bio_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T09:52:06.137752Z",
     "iopub.status.busy": "2025-01-27T09:52:06.137037Z",
     "iopub.status.idle": "2025-01-27T09:52:12.198840Z",
     "shell.execute_reply": "2025-01-27T09:52:12.198159Z",
     "shell.execute_reply.started": "2025-01-27T09:52:06.137728Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title Load Libraries\n",
    "from torch_geometric.data import Dataset\n",
    "import glob\n",
    "from torch_geometric.data import data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/working/bio_project/src/bio_project\")\n",
    "import argparse\n",
    "import wandb\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "import torch\n",
    "import os\n",
    "import wandb\n",
    "from argparse import Namespace\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T09:52:12.200576Z",
     "iopub.status.busy": "2025-01-27T09:52:12.200276Z",
     "iopub.status.idle": "2025-01-27T09:52:12.204014Z",
     "shell.execute_reply": "2025-01-27T09:52:12.203416Z",
     "shell.execute_reply.started": "2025-01-27T09:52:12.200548Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_root=\"/kaggle/input/embeddings-final/final_embeddings/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T09:52:12.205504Z",
     "iopub.status.busy": "2025-01-27T09:52:12.205163Z",
     "iopub.status.idle": "2025-01-27T09:52:12.368939Z",
     "shell.execute_reply": "2025-01-27T09:52:12.368066Z",
     "shell.execute_reply.started": "2025-01-27T09:52:12.205471Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-d7b681704474>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.slides=[torch.load(self.data[idx]) for idx in range(len(self.data))]\n"
     ]
    }
   ],
   "source": [
    "# @title Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,root,data_type):\n",
    "        self.path=os.path.join(root,data_type,\"*\")\n",
    "        self.data=glob.glob(self.path)\n",
    "        self.slides=[torch.load(self.data[idx]) for idx in range(len(self.data))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.slides[idx]\n",
    "        return sample\n",
    "        \n",
    "train_dataset=CustomDataset(data_root,\"train\")\n",
    "test_dataset=CustomDataset(data_root,\"test\")\n",
    "train_loader=DataLoader(train_dataset,batch_size=1,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T09:52:29.546978Z",
     "iopub.status.busy": "2025-01-27T09:52:29.546644Z",
     "iopub.status.idle": "2025-01-27T09:52:30.217525Z",
     "shell.execute_reply": "2025-01-27T09:52:30.216849Z",
     "shell.execute_reply.started": "2025-01-27T09:52:29.546949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.test import test\n",
    "from models import selectModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T09:52:32.346139Z",
     "iopub.status.busy": "2025-01-27T09:52:32.345655Z",
     "iopub.status.idle": "2025-01-27T09:52:32.358216Z",
     "shell.execute_reply": "2025-01-27T09:52:32.357212Z",
     "shell.execute_reply.started": "2025-01-27T09:52:32.346117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title General Parser\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Train Buffermil')\n",
    "\n",
    "    # Optimization arguments\n",
    "    group1 = parser.add_argument_group(\"optimization\")\n",
    "    group1.add_argument('--lr', default=0.00001,\n",
    "                        type=float, help='learning rate')\n",
    "    group1.add_argument('--weight_decay', default=0.00001,\n",
    "                        type=float, help='Weight decay [5e-3]')\n",
    "\n",
    "    # GNN arguments\n",
    "    group2 = parser.add_argument_group(\"gnn\")\n",
    "    group2.add_argument('--residual', default=False, action=\"store_true\",)\n",
    "    group2.add_argument('--num_layers', default=1, type=int,\n",
    "                        help='number of Graph layers')\n",
    "    group2.add_argument('--dropout', default=True, action=\"store_true\")\n",
    "    group2.add_argument('--dropout_rate', default=0.2, type=float)\n",
    "    group2.add_argument('--layer_name', default=\"GAT\",\n",
    "                        type=str, help='layer graph name')\n",
    "    group2.add_argument('--heads', default=3, type=int,\n",
    "                        help='layer graph name')\n",
    "\n",
    "    # Training arguments\n",
    "    group3 = parser.add_argument_group(\"training\")\n",
    "    group3.add_argument('--seed', default=12, type=int,\n",
    "                        help='seed for reproducibility')\n",
    "    group3.add_argument('--n_epoch', default=500,\n",
    "                        type=int, help='number of epochs')\n",
    "\n",
    "    # Dimensions arguments\n",
    "    group4 = parser.add_argument_group(\"dimensions\")\n",
    "    group4.add_argument('--n_classes', default=1, type=int,\n",
    "                        help='Number of output classes [2]')\n",
    "    group4.add_argument('--c_hidden', default=256,\n",
    "                        type=int, help='intermediate size ')\n",
    "    group4.add_argument('--input_size', default=384,\n",
    "                        type=int, help='input size ')\n",
    "\n",
    "    # Dataset arguments\n",
    "    group5 = parser.add_argument_group(\"dataset\")\n",
    "    group5.add_argument('--scale', default=\"0\", type=str,\n",
    "                        help='scale resolution')\n",
    "    group5.add_argument('--dataset', default=\"cam\", type=str,\n",
    "                        choices=[\"cam\", \"lung\"], help='input size ')\n",
    "    group5.add_argument('--datasetpath',  type=str, help='dataset path')\n",
    "\n",
    "    # Distillation arguments\n",
    "    group6 = parser.add_argument_group(\"distillation\")\n",
    "    group6.add_argument('--lamb', default=1, type=float, help='lambda')\n",
    "    group6.add_argument('--beta', default=1, type=float, help='beta')\n",
    "    group6.add_argument('--temperature', default=1.5, type=float, help='temperature')\n",
    "    group6.add_argument('--add_bias', default=True, action=\"store_true\")\n",
    "    group6.add_argument('--max', default=True, action=\"store_true\")\n",
    "    group6.add_argument('--checkpoint', default=None, type=str, help='checkpoint')\n",
    "\n",
    "    parser.add_argument('--tag', default=\"split\", type=str, help='train strategy')\n",
    "    parser.add_argument('--modeltype', default=\"Buffermil\", type=str, help='train strategy')\n",
    "    parser.add_argument('--project', default=\"bio_project\", type=str, help='project name for wandb')\n",
    "    parser.add_argument('--model', default=\"bio_project\", type=str, help='project name for wandb')\n",
    "    parser.add_argument('--wandbname', default=\"main\", type=str, help='project name for wandb')\n",
    "\n",
    "    group7 = parser.add_argument_group(\"submitit\")\n",
    "    group7.add_argument('--partition', default=\"prod\",type=str,help='partition name')\n",
    "    group7.add_argument('--time', default=120, type=float, help='job duration')\n",
    "    group7.add_argument('--nodes', default=1, type=int, help='number of jobs')\n",
    "    group7.add_argument('--job_name', default=\"dasmil\",type=str,help=\"job name\")\n",
    "    group7.add_argument('--mem', default=32, type=int, help='ram requested GB')\n",
    "    group7.add_argument('--job_parallel', default=10, type=int, help='number of jobs in parallel')\n",
    "    group7.add_argument('--logfolder', default=\"logfolder\", type=str, help='log folder location name')\n",
    "\n",
    "    # Buffermil parameters\n",
    "    group8 = parser.add_argument_group(\"submitit\")\n",
    "    group8.add_argument(\"--randomstore\", default=False, help=\"ramdom sampling during the buffer storage\")\n",
    "    group8.add_argument(\"--bufferaggregate\", default=\"mean\", choices=[\"mean\",\"max\",\"diffmax\"], help=\"type of buffer aggregation\")\n",
    "    group8.add_argument(\"--ntop\", default=10, help=\"number of patches stored in the buffer per each image\")\n",
    "    group8.add_argument('--buffer_freq', default=10, type=int, help='frequency to update the buffer')\n",
    "    \n",
    "    filtered_args = [arg for arg in sys.argv if not arg.startswith('-f')]\n",
    "    args = parser.parse_args(filtered_args[2:])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T09:52:34.386255Z",
     "iopub.status.busy": "2025-01-27T09:52:34.385974Z",
     "iopub.status.idle": "2025-01-27T09:52:34.392533Z",
     "shell.execute_reply": "2025-01-27T09:52:34.391645Z",
     "shell.execute_reply.started": "2025-01-27T09:52:34.386234Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(lr=1e-05, weight_decay=1e-05, residual=False, num_layers=1, dropout=True, dropout_rate=0.2, layer_name='GAT', heads=3, seed=12, n_epoch=500, n_classes=1, c_hidden=256, input_size=384, scale='0', dataset='cam', datasetpath=None, lamb=1, beta=1, temperature=1.5, add_bias=True, max=True, checkpoint=None, tag='split', modeltype='Buffermil', project='bio_project', model='bio_project', wandbname='main', partition='prod', time=120, nodes=1, job_name='dasmil', mem=32, job_parallel=10, logfolder='logfolder', randomstore=False, bufferaggregate='mean', ntop=10, buffer_freq=10)\n"
     ]
    }
   ],
   "source": [
    "args = get_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T09:53:05.599310Z",
     "iopub.status.busy": "2025-01-27T09:53:05.599023Z",
     "iopub.status.idle": "2025-01-27T09:53:05.608046Z",
     "shell.execute_reply": "2025-01-27T09:53:05.607124Z",
     "shell.execute_reply.started": "2025-01-27T09:53:05.599289Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f0bf2face44729aec0546e214a9c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Choose:', options=('Buffermil', 'CustomBuffermil'), value='Buffermil')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Select Model\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Crea un menu a discesa\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=[\"Buffermil\", \"CustomBuffermil\"],\n",
    "    value='Buffermil',\n",
    "    description='Choose:',\n",
    ")\n",
    "\n",
    "# Mostra il widget\n",
    "display(dropdown)\n",
    "\n",
    "# Recupera il valore selezionato\n",
    "def on_value_change(change):\n",
    "    print(f\"Selected: {change['new']}\")\n",
    "\n",
    "dropdown.observe(on_value_change, names='value')\n",
    "args.modeltype = dropdown.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T09:53:09.853328Z",
     "iopub.status.busy": "2025-01-27T09:53:09.853011Z",
     "iopub.status.idle": "2025-01-27T09:53:10.090800Z",
     "shell.execute_reply": "2025-01-27T09:53:10.090090Z",
     "shell.execute_reply.started": "2025-01-27T09:53:09.853301Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Buffermil\n",
      "error loading state dict\n",
      "error loading\n",
      "Number of parameters: 345730\n",
      "Memory usage: 0.001383936 GB\n"
     ]
    }
   ],
   "source": [
    "model = selectModel(args)\n",
    "model.kl = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T09:53:10.458258Z",
     "iopub.status.busy": "2025-01-27T09:53:10.457993Z",
     "iopub.status.idle": "2025-01-27T09:53:10.463093Z",
     "shell.execute_reply": "2025-01-27T09:53:10.462088Z",
     "shell.execute_reply.started": "2025-01-27T09:53:10.458237Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffermil(\n",
      "  (mil): MILNetBuffer(\n",
      "    (i_classifier): FCLayer(\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=384, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (b_classifier): BClassifierBuffer(\n",
      "      (lin): Sequential(\n",
      "        (0): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (q): Sequential(\n",
      "        (0): Linear(in_features=384, out_features=128, bias=True)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "      (v): Sequential(\n",
      "        (0): Dropout(p=0.0, inplace=False)\n",
      "        (1): Linear(in_features=384, out_features=384, bias=True)\n",
      "      )\n",
      "      (fcc): Conv1d(1, 1, kernel_size=(384,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T09:53:13.774091Z",
     "iopub.status.busy": "2025-01-27T09:53:13.773807Z",
     "iopub.status.idle": "2025-01-27T09:53:13.783220Z",
     "shell.execute_reply": "2025-01-27T09:53:13.782389Z",
     "shell.execute_reply.started": "2025-01-27T09:53:13.774070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title Training Method\n",
    "def train(model,train_loader,test_loader,args):\n",
    "    # Initialize wandb run\n",
    "    run = wandb.init(project=\"bio_project_v4\", name=args.modeltype)\n",
    "    epochs = args.n_epoch\n",
    "    wd = args.weight_decay\n",
    "    lr = args.lr\n",
    "    model.train()\n",
    "    model = model.cuda()\n",
    "    loss_module_instance = BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=wd)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    # Test the initial model\n",
    "    with torch.no_grad():\n",
    "        start_test = time.time()\n",
    "        metrics = test(model, testloader=test_loader)\n",
    "        end_test = time.time()\n",
    "        avg_score_higher_test, avg_score_lower_test, auc_value_higher_test, auc_value_lower_test, predictions, _, labels = metrics\n",
    "\n",
    "        wandb.log({\n",
    "            \"acc_higher_test\": avg_score_higher_test,\n",
    "            \"acc_lower_test\": avg_score_lower_test,\n",
    "            \"auc_higher_test\": auc_value_higher_test,\n",
    "            \"epoch\": -1,\n",
    "            \"lr\": scheduler.get_last_lr()[0]\n",
    "        })\n",
    "        \n",
    "    BestPerformance = 0\n",
    "    # Start training\n",
    "    for idx,epoch in tqdm.tqdm(enumerate(range(epochs)), desc=\"epochs\"):\n",
    "        start_training = time.time()\n",
    "        if hasattr(model, \"preloop\"):\n",
    "            model.preloop(epoch, train_loader)\n",
    "        # Iterate over the training data\n",
    "        for _, data in enumerate(train_loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            data = data.cuda()\n",
    "            x, edge_index, childof, level = data.x, data.edge_index, data.childof, data.level\n",
    "            \n",
    "            # Check if additional edge indices are present\n",
    "            if data.__contains__(\"edge_index_2\") and data.__contains__(\"edge_index_3\"):\n",
    "                edge_index2, edge_index3 = data.edge_index_2, data.edge_index_3\n",
    "            else:\n",
    "                edge_index2 = None\n",
    "                edge_index3 = None\n",
    "\n",
    "            try:\n",
    "                results = model(x, edge_index, level, childof, edge_index2, edge_index3)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            bag_label = data.y.float()\n",
    "            loss = model.compute_loss(loss_module_instance, results, bag_label)\n",
    "            wandb.log({\"loss\": loss})\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        end_training = time.time()\n",
    "        scheduler.step()\n",
    "        start_test = time.time()\n",
    "        metrics = test(model, testloader=test_loader)\n",
    "        end_test = time.time()\n",
    "        avg_score_higher_test, avg_score_lower_test, auc_value_higher_test, auc_value_lower_test, predictions, _, labels = metrics\n",
    "\n",
    "        wandb.log({\n",
    "            \"acc_higher_test\": avg_score_higher_test,\n",
    "            \"acc_lower_test\": avg_score_lower_test,\n",
    "            \"auc_higher_test\": auc_value_higher_test,\n",
    "            \"epoch\": epoch,\n",
    "            \"lr\": scheduler.get_last_lr()[0]\n",
    "        })\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T09:53:25.466234Z",
     "iopub.status.busy": "2025-01-27T09:53:25.465760Z",
     "iopub.status.idle": "2025-01-27T09:54:25.990598Z",
     "shell.execute_reply": "2025-01-27T09:54:25.989959Z",
     "shell.execute_reply.started": "2025-01-27T09:53:25.466209Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250127_095325-qfsps4to</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andrea-grandi-unimore/bio_project_v4/runs/qfsps4to' target=\"_blank\">Buffermil</a></strong> to <a href='https://wandb.ai/andrea-grandi-unimore/bio_project_v4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andrea-grandi-unimore/bio_project_v4' target=\"_blank\">https://wandb.ai/andrea-grandi-unimore/bio_project_v4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andrea-grandi-unimore/bio_project_v4/runs/qfsps4to' target=\"_blank\">https://wandb.ai/andrea-grandi-unimore/bio_project_v4/runs/qfsps4to</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 500it [00:51,  9.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc_higher_test</td><td>▁███████████████████████████████████████</td></tr><tr><td>acc_lower_test</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>auc_higher_test</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>loss</td><td>▅▄█▄█▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>██████████▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc_higher_test</td><td>0.75</td></tr><tr><td>acc_lower_test</td><td>0</td></tr><tr><td>auc_higher_test</td><td>0.66667</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>loss</td><td>0.00725</td></tr><tr><td>lr</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Buffermil</strong> at: <a href='https://wandb.ai/andrea-grandi-unimore/bio_project_v4/runs/qfsps4to' target=\"_blank\">https://wandb.ai/andrea-grandi-unimore/bio_project_v4/runs/qfsps4to</a><br> View project at: <a href='https://wandb.ai/andrea-grandi-unimore/bio_project_v4' target=\"_blank\">https://wandb.ai/andrea-grandi-unimore/bio_project_v4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250127_095325-qfsps4to/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Start Training\n",
    "train(model, train_loader, test_loader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T09:53:16.956782Z",
     "iopub.status.busy": "2025-01-27T09:53:16.956481Z",
     "iopub.status.idle": "2025-01-27T09:53:23.281307Z",
     "shell.execute_reply": "2025-01-27T09:53:23.280507Z",
     "shell.execute_reply.started": "2025-01-27T09:53:16.956761Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrea-grandi\u001b[0m (\u001b[33mandrea-grandi-unimore\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"d350c1926691a1f8b36ff558c9a28e9425f84fde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6539924,
     "sourceId": 10568786,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
