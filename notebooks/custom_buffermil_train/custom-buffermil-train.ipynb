{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10568786,"sourceType":"datasetVersion","datasetId":6539924}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# @title Prepare Environment\nimport torch\nimport os\nos.environ['TORCH'] = torch.__version__\nprint(torch.__version__)\n\n#!pip install torch-scatter\n!pip install torch-geometric\n!pip install nystrom-attention\n!pip install tensorboard\n!git clone https://github.com/andrea-grandi/bio_project\n!cd bio_project","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-24T10:25:04.774458Z","iopub.execute_input":"2025-01-24T10:25:04.774842Z","iopub.status.idle":"2025-01-24T10:26:47.058711Z","shell.execute_reply.started":"2025-01-24T10:25:04.774812Z","shell.execute_reply":"2025-01-24T10:26:47.057476Z"}},"outputs":[{"name":"stdout","text":"2.5.1+cu121\nCollecting torch-geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.10)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.9.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.12.14)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.6.1\nCollecting nystrom-attention\n  Downloading nystrom_attention-0.0.12-py3-none-any.whl.metadata (657 bytes)\nRequirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from nystrom-attention) (0.8.0)\nRequirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from nystrom-attention) (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->nystrom-attention) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->nystrom-attention) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->nystrom-attention) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->nystrom-attention) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->nystrom-attention) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->nystrom-attention) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0->nystrom-attention) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->nystrom-attention) (3.0.2)\nDownloading nystrom_attention-0.0.12-py3-none-any.whl (4.6 kB)\nInstalling collected packages: nystrom-attention\nSuccessfully installed nystrom-attention-0.0.12\nRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\nRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (24.2)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.12.0->tensorboard) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.12.0->tensorboard) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\nCloning into 'bio_project'...\nremote: Enumerating objects: 8437, done.\u001b[K\nremote: Counting objects: 100% (350/350), done.\u001b[K\nremote: Compressing objects: 100% (207/207), done.\u001b[K\nremote: Total 8437 (delta 145), reused 304 (delta 120), pack-reused 8087 (from 1)\u001b[K\nReceiving objects: 100% (8437/8437), 588.00 MiB | 7.04 MiB/s, done.\nResolving deltas: 100% (813/813), done.\nUpdating files: 100% (2378/2378), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# @title Load Libraries\nfrom torch_geometric.data import Dataset\nimport glob\nfrom torch_geometric.data import data\nfrom torch_geometric.loader import DataLoader\nimport sys\nsys.path.append(\"/kaggle/working/bio_project/src/bio_project\")\nimport argparse\nimport wandb\nfrom torch.nn import BCEWithLogitsLoss\nimport torch\nimport os\nimport wandb\nfrom argparse import Namespace\nimport time\nimport tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T10:26:47.060225Z","iopub.execute_input":"2025-01-24T10:26:47.060862Z","iopub.status.idle":"2025-01-24T10:26:53.193063Z","shell.execute_reply.started":"2025-01-24T10:26:47.060838Z","shell.execute_reply":"2025-01-24T10:26:53.192434Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data_root=\"/kaggle/input/embeddings-final/final_embeddings/processed\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T10:27:02.545893Z","iopub.execute_input":"2025-01-24T10:27:02.546193Z","iopub.status.idle":"2025-01-24T10:27:02.550122Z","shell.execute_reply.started":"2025-01-24T10:27:02.546171Z","shell.execute_reply":"2025-01-24T10:27:02.549200Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# @title Dataset\nclass CustomDataset(Dataset):\n    def __init__(self,root,data_type):\n        self.path=os.path.join(root,data_type,\"*\")\n        self.data=glob.glob(self.path)\n        #print(self.data)\n        self.slides=[torch.load(self.data[idx]) for idx in range(len(self.data))]\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        sample = self.slides[idx]\n        return sample\n        \ntrain_dataset=CustomDataset(data_root,\"train\")\ntest_dataset=CustomDataset(data_root,\"test\")\ntrain_loader=DataLoader(train_dataset,batch_size=1,shuffle=True)\ntest_loader=DataLoader(test_dataset,batch_size=1,shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T10:27:02.980235Z","iopub.execute_input":"2025-01-24T10:27:02.980600Z","iopub.status.idle":"2025-01-24T10:27:03.097021Z","shell.execute_reply.started":"2025-01-24T10:27:02.980570Z","shell.execute_reply":"2025-01-24T10:27:03.096126Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-4-c84b36c87000>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.slides=[torch.load(self.data[idx]) for idx in range(len(self.data))]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from utils.test import test\nfrom models import selectModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T10:27:04.856953Z","iopub.execute_input":"2025-01-24T10:27:04.857255Z","iopub.status.idle":"2025-01-24T10:27:05.525055Z","shell.execute_reply.started":"2025-01-24T10:27:04.857234Z","shell.execute_reply":"2025-01-24T10:27:05.524130Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# @title General Parser\ndef get_args():\n    parser = argparse.ArgumentParser(description='Train Buffermil')\n\n    # Optimization arguments\n    group1 = parser.add_argument_group(\"optimization\")\n    group1.add_argument('--lr', default=0.0004,\n                        type=float, help='learning rate')\n    group1.add_argument('--weight_decay', default=0.001,\n                        type=float, help='Weight decay [5e-3]')\n\n    # GNN arguments\n    group2 = parser.add_argument_group(\"gnn\")\n    group2.add_argument('--residual', default=False, action=\"store_true\",)\n    group2.add_argument('--num_layers', default=1, type=int,\n                        help='number of Graph layers')\n    group2.add_argument('--dropout', default=True, action=\"store_true\")\n    group2.add_argument('--dropout_rate', default=0.2, type=float)\n    group2.add_argument('--layer_name', default=\"GAT\",\n                        type=str, help='layer graph name')\n    group2.add_argument('--heads', default=3, type=int,\n                        help='layer graph name')\n\n    # Training arguments\n    group3 = parser.add_argument_group(\"training\")\n    group3.add_argument('--seed', default=12, type=int,\n                        help='seed for reproducibility')\n    group3.add_argument('--n_epoch', default=100,\n                        type=int, help='number of epochs')\n\n    # Dimensions arguments\n    group4 = parser.add_argument_group(\"dimensions\")\n    group4.add_argument('--n_classes', default=1, type=int,\n                        help='Number of output classes [2]')\n    group4.add_argument('--c_hidden', default=256,\n                        type=int, help='intermediate size ')\n    group4.add_argument('--input_size', default=384,\n                        type=int, help='input size ')\n\n    # Dataset arguments\n    group5 = parser.add_argument_group(\"dataset\")\n    group5.add_argument('--scale', default=\"0\", type=str,\n                        help='scale resolution')\n    group5.add_argument('--dataset', default=\"cam\", type=str,\n                        choices=[\"cam\", \"lung\"], help='input size ')\n    group5.add_argument('--datasetpath',  type=str, help='dataset path')\n\n    # Distillation arguments\n    group6 = parser.add_argument_group(\"distillation\")\n    group6.add_argument('--lamb', default=1, type=float, help='lambda')\n    group6.add_argument('--beta', default=1, type=float, help='beta')\n    group6.add_argument('--temperature', default=1.5, type=float, help='temperature')\n    group6.add_argument('--add_bias', default=True,action=\"store_true\")\n    group6.add_argument('--max', default=True,action=\"store_true\")\n    group6.add_argument('--checkpoint', default=None,type=str, help='checkpoint')\n\n    parser.add_argument('--tag', default=\"split\", type=str, help='train strategy')\n    parser.add_argument('--modeltype', default=\"Buffermil\", type=str, help='train strategy')\n    parser.add_argument('--project', default=\"decider-geom\", type=str, help='project name for wandb')\n    parser.add_argument('--model', default=\"decider-geom\", type=str, help='project name for wandb')\n    parser.add_argument('--wandbname', default=\"main\", type=str, help='project name for wandb')\n\n    group7 = parser.add_argument_group(\"submitit\")\n    group7.add_argument('--partition', default=\"prod\",type=str,help='partition name')\n    group7.add_argument('--time', default=120, type=float, help='job duration')\n    group7.add_argument('--nodes', default=1, type=int, help='number of jobs')\n    group7.add_argument('--job_name', default=\"dasmil\",type=str,help=\"job name\")\n    group7.add_argument('--mem', default=32, type=int, help='ram requested GB')\n    group7.add_argument('--job_parallel', default=10, type=int, help='number of jobs in parallel')\n    group7.add_argument('--logfolder', default=\"logfolder\", type=str, help='log folder location name')\n\n    #buffermil parameters\n    group8 = parser.add_argument_group(\"submitit\")\n    group8.add_argument(\"--randomstore\", default=False, help=\"ramdom sampling during the buffer storage\")\n    group8.add_argument(\"--bufferaggregate\", default=\"mean\", choices=[\"mean\",\"max\",\"diffmax\"], help=\"type of buffer aggregation\")\n    group8.add_argument(\"--ntop\", default=10, help=\"number of patches stored in the buffer per each image\")\n    group8.add_argument('--buffer_freq', default=10, type=int, help='frequency to update the buffer')\n    \n    filtered_args = [arg for arg in sys.argv if not arg.startswith('-f')]\n    args = parser.parse_args(filtered_args[2:])\n    return args","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T10:36:17.205981Z","iopub.execute_input":"2025-01-24T10:36:17.206372Z","iopub.status.idle":"2025-01-24T10:36:17.219268Z","shell.execute_reply.started":"2025-01-24T10:36:17.206345Z","shell.execute_reply":"2025-01-24T10:36:17.218294Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"args = get_args()\nprint(args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T10:36:18.029939Z","iopub.execute_input":"2025-01-24T10:36:18.030259Z","iopub.status.idle":"2025-01-24T10:36:18.036514Z","shell.execute_reply.started":"2025-01-24T10:36:18.030233Z","shell.execute_reply":"2025-01-24T10:36:18.035757Z"}},"outputs":[{"name":"stdout","text":"Namespace(lr=0.0004, weight_decay=0.001, residual=False, num_layers=1, dropout=True, dropout_rate=0.2, layer_name='GAT', heads=3, seed=12, n_epoch=100, n_classes=1, c_hidden=256, input_size=384, scale='0', dataset='cam', datasetpath=None, lamb=1, beta=1, temperature=1.5, add_bias=True, max=True, checkpoint=None, tag='split', modeltype='Buffermil', project='decider-geom', model='decider-geom', wandbname='main', partition='prod', time=120, nodes=1, job_name='dasmil', mem=32, job_parallel=10, logfolder='logfolder', randomstore=False, bufferaggregate='mean', ntop=10, buffer_freq=10)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# @title Select Model\nimport ipywidgets as widgets\nfrom IPython.display import display\n\n# Crea un menu a discesa\ndropdown = widgets.Dropdown(\n\n    options=[\"Buffermil\"],\n    value='Buffermil',\n    description='Choose:',\n)\n\n# Mostra il widget\ndisplay(dropdown)\n\n# Recupera il valore selezionato\ndef on_value_change(change):\n    print(f\"Selected: {change['new']}\")\n\ndropdown.observe(on_value_change, names='value')\nargs.modeltype = dropdown.value","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T10:36:20.233408Z","iopub.execute_input":"2025-01-24T10:36:20.233779Z","iopub.status.idle":"2025-01-24T10:36:20.243389Z","shell.execute_reply.started":"2025-01-24T10:36:20.233740Z","shell.execute_reply":"2025-01-24T10:36:20.242223Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Dropdown(description='Choose:', options=('Buffermil',), value='Buffermil')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"903df64433b64f19b60d7908b59482a0"}},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"model = selectModel(args)\nmodel.kl = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T10:36:20.584943Z","iopub.execute_input":"2025-01-24T10:36:20.585257Z","iopub.status.idle":"2025-01-24T10:36:20.596763Z","shell.execute_reply.started":"2025-01-24T10:36:20.585234Z","shell.execute_reply":"2025-01-24T10:36:20.595939Z"}},"outputs":[{"name":"stdout","text":"model Buffermil\nerror loading state dict\nerror loading\nNumber of parameters: 345730\nMemory usage: 0.02134272 GB\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T10:36:21.009664Z","iopub.execute_input":"2025-01-24T10:36:21.009985Z","iopub.status.idle":"2025-01-24T10:36:21.014885Z","shell.execute_reply.started":"2025-01-24T10:36:21.009958Z","shell.execute_reply":"2025-01-24T10:36:21.013892Z"}},"outputs":[{"name":"stdout","text":"CustomBuffermil(\n  (mil): MILNetBuffer(\n    (i_classifier): FCLayer(\n      (fc): Sequential(\n        (0): Linear(in_features=384, out_features=1, bias=True)\n      )\n    )\n    (b_classifier): BClassifierBuffer(\n      (lin): Sequential(\n        (0): Linear(in_features=384, out_features=384, bias=True)\n        (1): ReLU()\n      )\n      (q): Sequential(\n        (0): Linear(in_features=384, out_features=128, bias=True)\n        (1): Tanh()\n      )\n      (v): Sequential(\n        (0): Dropout(p=0.0, inplace=False)\n        (1): Linear(in_features=384, out_features=384, bias=True)\n      )\n      (fcc): Conv1d(1, 1, kernel_size=(384,), stride=(1,))\n    )\n  )\n)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# @title Training Method\ndef train(model,train_loader,test_loader,args):\n    # Initialize wandb run\n    print(\"INIT WANDB...\")\n    run = wandb.init(project=\"bio_project_v2\", name=args.modeltype)\n    print(\"WANDB INITIALIZED!\")\n    epochs = args.n_epoch\n    wd = args.weight_decay\n    lr = args.lr\n    model.train()\n    model = model.cuda()\n    loss_module_instance = BCEWithLogitsLoss()\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(\n        0.5, 0.9), weight_decay=wd)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, 0.000005)\n    # Test the initial model\n    with torch.no_grad():\n        start_test = time.time()\n        metrics = test(model, testloader=test_loader)\n        end_test = time.time()\n        avg_score_higher_test, avg_score_lower_test, auc_value_higher_test, auc_value_lower_test, predictions, _, labels = metrics\n\n        wandb.log({\n            \"acc_higher_test\": avg_score_higher_test,\n            \"acc_lower_test\": avg_score_lower_test,\n            \"auc_higher_test\": auc_value_higher_test,\n            \"epoch\": -1,\n            \"lr\": scheduler.get_last_lr()[0]\n        })\n        \n    BestPerformance = 0\n    # Start training\n    for idx,epoch in tqdm.tqdm(enumerate(range(epochs)), desc=\"epochs\"):\n        start_training = time.time()\n        if hasattr(model, \"preloop\"):\n            model.preloop(epoch, train_loader)\n        # Iterate over the training data\n        for _, data in enumerate(train_loader):\n            model.train()\n            optimizer.zero_grad()\n            data = data.cuda()\n            x, edge_index, childof, level = data.x, data.edge_index, data.childof, data.level\n            \n            # Check if additional edge indices are present\n            if data.__contains__(\"edge_index_2\") and data.__contains__(\"edge_index_3\"):\n                edge_index2, edge_index3 = data.edge_index_2, data.edge_index_3\n            else:\n                edge_index2 = None\n                edge_index3 = None\n\n            try:\n                results = model(x, edge_index, level, childof, edge_index2, edge_index3)\n            except:\n                continue\n                \n            bag_label = data.y.float()\n            loss = model.compute_loss(loss_module_instance, results, bag_label)\n            wandb.log({\"loss\": loss})\n            loss.backward()\n            optimizer.step()\n            \n        end_training = time.time()\n        scheduler.step()\n        start_test = time.time()\n        metrics = test(model, testloader=test_loader)\n        end_test = time.time()\n        avg_score_higher_test, avg_score_lower_test, auc_value_higher_test, auc_value_lower_test, predictions, _, labels = metrics\n\n        wandb.log({\n            \"acc_higher_test\": avg_score_higher_test,\n            \"acc_lower_test\": avg_score_lower_test,\n            \"auc_higher_test\": auc_value_higher_test,\n            \"epoch\": epoch,\n            \"lr\": scheduler.get_last_lr()[0]\n        })\n\n    wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T10:36:22.393115Z","iopub.execute_input":"2025-01-24T10:36:22.393486Z","iopub.status.idle":"2025-01-24T10:36:22.403825Z","shell.execute_reply.started":"2025-01-24T10:36:22.393454Z","shell.execute_reply":"2025-01-24T10:36:22.402877Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# @title Start Training\ntrain(model, train_loader, test_loader, args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T10:36:24.273410Z","iopub.execute_input":"2025-01-24T10:36:24.273733Z","iopub.status.idle":"2025-01-24T10:36:43.810450Z","shell.execute_reply.started":"2025-01-24T10:36:24.273710Z","shell.execute_reply":"2025-01-24T10:36:43.809761Z"}},"outputs":[{"name":"stdout","text":"INIT WANDB...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250124_103624-269huts3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/andrea-grandi-unimore/bio_project_v2/runs/269huts3' target=\"_blank\">Buffermil</a></strong> to <a href='https://wandb.ai/andrea-grandi-unimore/bio_project_v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/andrea-grandi-unimore/bio_project_v2' target=\"_blank\">https://wandb.ai/andrea-grandi-unimore/bio_project_v2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/andrea-grandi-unimore/bio_project_v2/runs/269huts3' target=\"_blank\">https://wandb.ai/andrea-grandi-unimore/bio_project_v2/runs/269huts3</a>"},"metadata":{}},{"name":"stdout","text":"WANDB INITIALIZED!\n","output_type":"stream"},{"name":"stderr","text":"epochs: 9it [00:00,  9.48it/s]/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\nepochs: 19it [00:02,  9.45it/s]/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\nepochs: 29it [00:03,  9.26it/s]/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\nepochs: 39it [00:04,  9.25it/s]/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\nepochs: 49it [00:05,  8.69it/s]/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\nepochs: 59it [00:06,  9.39it/s]/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\nepochs: 69it [00:07,  8.05it/s]/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\nepochs: 79it [00:09,  9.16it/s]/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\nepochs: 89it [00:10,  9.44it/s]/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\nepochs: 99it [00:11,  9.55it/s]/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\n/kaggle/working/bio_project/src/bio_project/models/buffermil/custom_buffermil.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  _, m_indices = torch.sort(torch.tensor(scores).cuda(), 0, descending=True)  # sort scores, m_indices in shape N\nepochs: 100it [00:11,  8.63it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc_higher_test</td><td>▅▅█▅▅▅▅▅▅▅▁▅▅▅▁▅▅▅▅▁▁▅▅▁▅▁▁▅▅▁▅▁▁▁▁▁▁▁▁▁</td></tr><tr><td>acc_lower_test</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>auc_higher_test</td><td>▁█▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▅▅▅▅▅▅▁▅▅▁▅▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅█▃▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>█████████▇▇▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc_higher_test</td><td>0.5</td></tr><tr><td>acc_lower_test</td><td>0</td></tr><tr><td>auc_higher_test</td><td>0.33333</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>loss</td><td>0.00034</td></tr><tr><td>lr</td><td>1e-05</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">Buffermil</strong> at: <a href='https://wandb.ai/andrea-grandi-unimore/bio_project_v2/runs/269huts3' target=\"_blank\">https://wandb.ai/andrea-grandi-unimore/bio_project_v2/runs/269huts3</a><br> View project at: <a href='https://wandb.ai/andrea-grandi-unimore/bio_project_v2' target=\"_blank\">https://wandb.ai/andrea-grandi-unimore/bio_project_v2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250124_103624-269huts3/logs</code>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"wandb.login(key=\"d350c1926691a1f8b36ff558c9a28e9425f84fde\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-24T10:27:17.358966Z","iopub.execute_input":"2025-01-24T10:27:17.359253Z","iopub.status.idle":"2025-01-24T10:27:23.688065Z","shell.execute_reply.started":"2025-01-24T10:27:17.359230Z","shell.execute_reply":"2025-01-24T10:27:23.687384Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrea-grandi\u001b[0m (\u001b[33mandrea-grandi-unimore\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}