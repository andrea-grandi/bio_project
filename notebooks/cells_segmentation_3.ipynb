{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10319204,"sourceType":"datasetVersion","datasetId":6388821}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!python -m pip install pyyaml==5.1\nimport sys, os, distutils.core\n# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n!git clone 'https://github.com/facebookresearch/detectron2'\ndist = distutils.core.run_setup(\"./detectron2/setup.py\")\n!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\nsys.path.insert(0, os.path.abspath('./detectron2'))\n\n# Properly install detectron2. (Please do not install twice in both ways)\n# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch, detectron2\n!nvcc --version\nTORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\nCUDA_VERSION = torch.__version__.split(\"+\")[-1]\nprint(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\nprint(\"detectron2:\", detectron2.__version__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Some basic setup:\n# Setup detectron2 logger\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport numpy as np\nimport os, json, cv2, random\nfrom google.colab.patches import cv2_imshow\nfrom matplotlib import pyplot as plt\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.data.datasets import register_coco_instances","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"register_coco_instances(\"my_dataset_train\", {}, \"/kaggle/input/coco-dataset-5/TIL.v5i.coco/train/_annotations.coco.json\", \"/kaggle/input/coco-dataset-5/TIL.v5i.coco/train\")\nregister_coco_instances(\"my_dataset_val\", {}, \"/kaggle/input/coco-dataset-5/TIL.v5i.coco/valid/_annotations.coco.json\", \"/kaggle/input/coco-dataset-5/TIL.v5i.coco/valid\")\nregister_coco_instances(\"my_dataset_test\", {}, \"/kaggle/input/coco-dataset-5/TIL.v5i.coco/test/_annotations.coco.json\", \"/kaggle/input/coco-dataset-5/TIL.v5i.coco/test\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_metadata = MetadataCatalog.get(\"my_dataset_train\")\ntrain_dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_metadata = MetadataCatalog.get(\"my_dataset_val\")\nval_dataset_dicts = DatasetCatalog.get(\"my_dataset_val\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_metadata = MetadataCatalog.get(\"my_dataset_test\")\ntest_dataset_dicts = DatasetCatalog.get(\"my_dataset_test\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize some random samples\nfor d in random.sample(train_dataset_dicts, 1):\n    img = cv2.imread(d[\"file_name\"])\n    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=1)\n    vis = visualizer.draw_dataset_dict(d)\n    plt.imshow(vis.get_image()[:, :, ::-1])\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"from detectron2.engine import DefaultTrainer\n\ncfg = get_cfg()\ncfg.OUTPUT_DIR = \"/kaggle/working/models/Detectron2_Models\"\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"my_dataset_train\",)\ncfg.DATASETS.TEST = ()\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\ncfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\ncfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\ncfg.SOLVER.MAX_ITER = 5000    # 5000 iterations seems good enough for this dataset\ncfg.SOLVER.STEPS = []        # do not decay learning rate\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # Default is 512, using 256 for this dataset.\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  # We have 3 class\n# NOTE: this config means the number of classes, without the background. Do not use num_classes+1 here.\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = DefaultTrainer(cfg) #Create an instance of of DefaultTrainer with the given congiguration\ntrainer.resume_or_load(resume=False) #Load a pretrained model if available (resume training) or start training from scratch if no pretrained model is available","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train() #Start the training process","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import yaml\n# Save the configuration to a config.yaml file\nconfig_yaml_path = \"/kaggle/working/models/Detectron2_Models/config.yaml\"\nwith open(config_yaml_path, 'w') as file:\n    yaml.dump(cfg, file)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inference should use the config with parameters that are used in training\n# cfg now already contains everything we've set previously. We changed it a little bit for inference:\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\npredictor = DefaultPredictor(cfg)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from detectron2.utils.visualizer import ColorMode\n\nfor d in random.sample(val_dataset_dicts, 1):    #select number of images for display\n    im = cv2.imread(d[\"file_name\"])\n    outputs = predictor(im)\n    instances = outputs[\"instances\"].to(\"cpu\")\n    v = Visualizer(im[:, :, ::-1],\n                   metadata=val_metadata,\n                   scale=1\n    )\n    out = v.draw_instance_predictions(instances)\n    cv2_imshow(out.get_image()[:, :, ::-1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.data import build_detection_test_loader\nevaluator = COCOEvaluator(\"my_dataset_val\", output_dir=\"./output\")\nval_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\nprint(inference_on_dataset(predictor.model, val_loader, evaluator))\n# another equivalent way to evaluate the model is to use `trainer.test`","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test with new image\nnew_im = cv2.imread(\"/kaggle/input/coco-dataset-5/TIL.v5i.coco/test/146_image_png.rf.d544162a26ace1a67e988bc28fbdb313.jpg\")\nnew_im = cv2.resize(new_im, (256, 256))\nprint(new_im.shape)\n\noutputs = predictor(new_im)\ninstances = outputs[\"instances\"].to(\"cpu\")\n\nconfidence_threshold = 0.3\ninstances = instances[instances.scores > confidence_threshold]\n\nv = Visualizer(new_im[:, :, ::-1], metadata=train_metadata, scale=1)\nout = v.draw_instance_predictions(instances)\n\ncv2_imshow(out.get_image()[:, :, ::-1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TODO\n\n- Extracting cells number and density\n- Create csv metadata file containing this infos\n- Feature extraction ","metadata":{}},{"cell_type":"code","source":"\"\"\"\n# Directory path to the input images folder\ninput_images_directory = \"/kaggle/input/camelyon/dataset/patches\"\n\n# Output directory where the segmented images will be saved\noutput_directory = \"/kaggle/working/test_results/masks\"  # Replace this with the path to your desired output directory\nos.makedirs(output_directory, exist_ok=True)\n\n# Loop over the images in the input folder\ndef process_images_in_directory(input_dir, output_dir):\n    for root, _, files in os.walk(input_dir):\n        for file in files:\n            if file.endswith(('.png')): \n                image_path = os.path.join(root, file)\n                new_im = cv2.imread(image_path)\n\n                # Perform prediction on the new image\n                outputs = predictor(new_im)  # Replace `predictor` with your initialized model\n\n                # Use Visualizer to draw the predictions on the image\n                v = Visualizer(new_im[:, :, ::-1], metadata=train_metadata)\n                out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n\n                # Create the output path, maintaining the folder structure\n                relative_path = os.path.relpath(image_path, input_dir)\n                result_path = os.path.join(output_dir, os.path.splitext(relative_path)[0] + \"_result.png\")\n                os.makedirs(os.path.dirname(result_path), exist_ok=True)\n\n                # Save the segmented image\n                cv2.imwrite(result_path, out.get_image()[:, :, ::-1])\n                print(f\"Image at {image_path} processed\")\n\n# Process all images in the directory\nprocess_images_in_directory(input_images_directory, output_directory)\n\nprint(\"Segmentation of all images in subfolders completed.\")\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nimport csv\nimport os\nimport time\nimport re\nimport cv2\nimport numpy as np\n\n# Directory path to the input images folder\ninput_images_directory = \"/kaggle/input/custom-dataset/selected_patches\"\n\n# Output directory where the CSV file will be saved\noutput_csv_path = \"/kaggle/working/test_results/output_objects.csv\"\nos.makedirs(os.path.dirname(output_csv_path), exist_ok=True)\n\n# Gather all image paths\nimage_paths = []\nfor root, _, files in os.walk(input_images_directory):\n    for file in files:\n        if file.endswith('.png'):  # Process only PNG files\n            image_paths.append(os.path.join(root, file))\n\n# Function to extract patient, node, x, and y coordinates from file name\ndef parse_filename(file_name):\n    pattern = r\"patch_patient_(\\d+)_node_(\\d+)_x_(\\d+)_y_(\\d+)\"\n    match = re.search(pattern, file_name)\n    if match:\n        return match.group(1), match.group(2), match.group(3), match.group(4)\n    return None, None, None, None\n\n# Total number of images\ntotal_images = len(image_paths)\nprint(f\"Total Images: {total_images}\")\n\n# Open the CSV file for writing\nwith open(output_csv_path, 'w', newline='') as csvfile:\n    csvwriter = csv.writer(csvfile)\n\n    # Write the header row in the CSV file\n    csvwriter.writerow([\"patient\", \"node\", \"x_coord\", \"y_coord\", \"bounding_box\", \"area\", \"number_of_cells\", \"cell_density\"])\n\n    start_time = time.time()  # Record the start time of the entire process\n\n    # Loop over the images\n    for idx, image_path in enumerate(image_paths):\n        image_start_time = time.time()  # Start time for the current image\n        image = cv2.imread(image_path)\n\n        file_name = os.path.basename(image_path)\n        patient, node, x_coord, y_coord = parse_filename(file_name)\n\n        # Perform prediction on the image\n        outputs = predictor(image)  # Replace `predictor` with your initialized model\n\n        # Extract bounding boxes and scores\n        pred_boxes = outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n\n        # Calculate total area covered by all bounding boxes\n        total_area = 0\n        for box in pred_boxes:\n            box_area = (box[2] - box[0]) * (box[3] - box[1])\n            total_area += box_area\n\n        # Number of detected cells\n        num_cells = len(pred_boxes)\n\n        # Calculate cell density (number of cells per unit area)\n        cell_density = num_cells / total_area if total_area > 0 else 0\n\n        # Write information for each detected object\n        for bounding_box in pred_boxes:\n            area = (bounding_box[2] - bounding_box[0]) * (bounding_box[3] - bounding_box[1])  # Area of the bounding box\n\n            # Write the object information to the CSV file\n            csvwriter.writerow([\n                patient, node, x_coord, y_coord, \n                bounding_box.tolist(),  # Convert NumPy array to list\n                area, \n                num_cells, \n                cell_density\n            ])\n\n        # Calculate time taken for the current image\n        image_time_taken = time.time() - image_start_time\n\n        # Calculate estimated remaining time\n        images_processed = idx + 1\n        elapsed_time = time.time() - start_time\n        avg_time_per_image = elapsed_time / images_processed\n        remaining_time = avg_time_per_image * (total_images - images_processed)\n\n        # Print progress\n        print(f\"Processed {images_processed}/{total_images} images. \"\n              f\"Time for current image: {image_time_taken:.2f}s. \"\n              f\"Estimated time remaining: {remaining_time:.2f}s.\")\n\nprint(\"Object-level information saved to CSV file.\")\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport cv2\nimport numpy as np\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.structures import BoxMode\n\n# Funzione per caricare il modello e fare le predizioni\ndef get_detector():\n    cfg = get_cfg()\n    cfg.merge_from_file(\"/kaggle/working/models/Detectron2_Models/config.yaml\")  # Sostituisci con il percorso del tuo file di configurazione\n    cfg.MODEL.WEIGHTS = \"/kaggle/working/models/Detectron2_Models/model_final.pth\"  # Sostituisci con il percorso del tuo modello allenato\n    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Threshold per la predizione\n    predictor = DefaultPredictor(cfg)\n    return predictor\n\n# Funzione per analizzare la segmentazione\ndef analyze_segmentation(predictions, image):\n    # Estrazione delle istanze segmentate\n    instances = predictions[\"instances\"]\n    pred_classes = instances.pred_classes.cpu().numpy()\n    pred_masks = instances.pred_masks.cpu().numpy()\n    \n    # Calcolo delle caratteristiche richieste\n    num_cells = len(pred_classes)\n    cell_types = np.unique(pred_classes)  # Varietà cellulare (tipi di cellule unici)\n    \n    tumor_detected = 1 if 1 in cell_types else 0  # Se c'è almeno una cellula tumorale, la patch è tumorale\n    area_cells = sum([np.sum(mask) for mask in pred_masks])  # Area totale delle cellule segmentate\n    \n    return num_cells, cell_types, area_cells, tumor_detected\n\n# Funzione per elaborare un'immagine e raccogliere i metadati\ndef process_image(image_path, predictor):\n    image = cv2.imread(image_path)\n    predictions = predictor(image)\n    \n    num_cells, cell_types, area_cells, tumor_detected = analyze_segmentation(predictions, image)\n    \n    # Usa il nome del file come patch_id\n    patch_id = os.path.basename(image_path)\n    \n    # Crea un dizionario con i metadati della patch\n    metadata = {\n        \"patch_id\": patch_id,\n        \"num_cells\": num_cells,\n        \"cell_types\": \", \".join(map(str, cell_types)),  # Concatena i tipi di cellula unici\n        \"area_cells\": area_cells,\n        \"tumor_detected\": tumor_detected\n    }\n    \n    return metadata\n\n# Funzione per processare tutte le immagini in una cartella\ndef process_images_in_folder(folder_path, predictor):\n    metadata_list = []\n    \n    for root, _, files in os.walk(folder_path):\n        for file in files:\n            if file.endswith(\".png\") or file.endswith(\".jpg\"):\n                image_path = os.path.join(root, file)\n                metadata = process_image(image_path, predictor)\n                metadata_list.append(metadata)\n    \n    # Salva i metadati in un file CSV\n    df = pd.DataFrame(metadata_list)\n    df.to_csv(\"patch_metadata.csv\", index=False)\n\n\nif __name__ == \"__main__\":\n    folder_path = \"/kaggle/input/coco-dataset-5/TIL.v5i.coco\"  \n    predictor = get_detector()\n    process_images_in_folder(folder_path, predictor)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}