\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{8507932}
\citation{ilse2018attention,campanella2019clinical}
\citation{ilse2018attention}
\citation{litjens2017survey,campanella2019clinical}
\citation{lu2021clam}
\citation{stringer2021cellpose}
\citation{caron2021emerging}
\citation{campanella2019clinical}
\citation{ilse2018attention}
\citation{conf/midl/SharmaSEMSB21}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{li2021dualstreammultipleinstancelearning}
\citation{10.1007/978-3-031-43153-1_1}
\citation{fourkioti2023camil}
\citation{WANG2024109826}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\newlabel{related}{{2}{2}{Related Work}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{2}{section.3}\protected@file@percent }
\newlabel{methods}{{3}{2}{Methods}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Patch Extraction and Preprocessing}{2}{subsection.3.1}\protected@file@percent }
\citation{caron2021emerging}
\citation{dosovitskiy2021imageworth16x16words}
\citation{stringer2021cellpose}
\citation{ronneberger2015unetconvolutionalnetworksbiomedical}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Model architecture. a}, Procedure for transforming manually annotated masks into a vector flow representation that can be predicted by a neural network. A simulated diffusion process started at the center of the mask is used to derive spatial gradients that point towards the center of the cell, potentially indirectly around corners. The X and Y gradients are combined into a single normalized direction from 0 to 360. \textbf  {b}, Example spatial flows for cells from the training dataset. \textbf  {cd}, A neural network is trained to predict the horizontal and vertical flows, as well as whether a pixel belongs to any cell. The three predicted maps are combined into a flow field. \textbf  {d} shows the details of the neural network which contains a standard backbone neural network that downsamples and then upsamples the feature maps, contains skip connections between layers of the same size, and global skip connections from the image styles, computed at the lowest resolution, to all the successive computations. \textbf  {e}, At test time, the predicted flow fields are used to construct a dynamical system with fixed points whose basins of attraction represent the predicted masks. Informally, every pixel ”follows the flows” along the predicted flow fields towards their eventual fixed point. \textbf  {f}, All the pixels that converge to the same fixed point are assigned to the same mask.}}{3}{figure.1}\protected@file@percent }
\newlabel{cellpose}{{1}{3}{\textbf {Model architecture. a}, Procedure for transforming manually annotated masks into a vector flow representation that can be predicted by a neural network. A simulated diffusion process started at the center of the mask is used to derive spatial gradients that point towards the center of the cell, potentially indirectly around corners. The X and Y gradients are combined into a single normalized direction from 0 to 360. \textbf {b}, Example spatial flows for cells from the training dataset. \textbf {cd}, A neural network is trained to predict the horizontal and vertical flows, as well as whether a pixel belongs to any cell. The three predicted maps are combined into a flow field. \textbf {d} shows the details of the neural network which contains a standard backbone neural network that downsamples and then upsamples the feature maps, contains skip connections between layers of the same size, and global skip connections from the image styles, computed at the lowest resolution, to all the successive computations. \textbf {e}, At test time, the predicted flow fields are used to construct a dynamical system with fixed points whose basins of attraction represent the predicted masks. Informally, every pixel ”follows the flows” along the predicted flow fields towards their eventual fixed point. \textbf {f}, All the pixels that converge to the same fixed point are assigned to the same mask}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Feature Extraction}{3}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Visual Feature Extraction with DINO}{3}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Numerical Feature Extraction with Cellpose}{3}{subsubsection.3.2.2}\protected@file@percent }
\citation{10.1007/978-3-031-43153-1_1}
\bibstyle{unsrt}
\bibdata{references}
\bibcite{8507932}{1}
\bibcite{ilse2018attention}{2}
\bibcite{campanella2019clinical}{3}
\bibcite{litjens2017survey}{4}
\bibcite{lu2021clam}{5}
\bibcite{stringer2021cellpose}{6}
\bibcite{caron2021emerging}{7}
\bibcite{conf/midl/SharmaSEMSB21}{8}
\bibcite{li2021dualstreammultipleinstancelearning}{9}
\bibcite{10.1007/978-3-031-43153-1_1}{10}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Geometry Dataset Conversion}{4}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}BufferMIL Adaptation}{4}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Attention Mechanism}{4}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments and Results}{4}{section.4}\protected@file@percent }
\newlabel{results}{{4}{4}{Experiments and Results}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{4}{section.5}\protected@file@percent }
\newlabel{conclusions}{{5}{4}{Conclusions}{section.5}{}}
\bibcite{fourkioti2023camil}{11}
\bibcite{WANG2024109826}{12}
\bibcite{dosovitskiy2021imageworth16x16words}{13}
\bibcite{ronneberger2015unetconvolutionalnetworksbiomedical}{14}
\gdef \@abspage@last{5}
