\documentclass[10pt,twocolumn]{article}

% Pacchetti di base
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\geometry{a4paper, left=1.5cm, right=1.5cm, top=2cm, bottom=2cm}

% Pacchetti aggiuntivi
\usepackage{graphicx} % Per inserire immagini
\usepackage{amsmath, amssymb} % Per simboli matematici
\usepackage{hyperref} % Per collegamenti ipertestuali
\usepackage{titlesec} % Per personalizzare i titoli
\usepackage{abstract} % Per formattare l'abstract
\usepackage{cite} 

% Impostazioni dei titoli delle sezioni
\titleformat{\section}{\Large\bfseries}{\thesection.}{1em}{}
\titleformat{\subsection}{\large\bfseries}{\thesubsection.}{1em}{}

% Intestazione e piede di pagina
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[C]{Multiple instance learning with pre-contextual knowledge - Andrea Grandi, Daniele Vellani}
\fancyfoot[C]{\thepage}

% Dati del documento
\title{\textbf{Multiple instance learning with pre-contextual knowledge}}
\author{Andrea Grandi, Daniele Vellani \\
\texttt{\{275074,196186\}@studenti.unimore.it}}
\date{Data}

\begin{document}

% Titolo e Autore
\maketitle

% Abstract
\begin{abstract}
\noindent 
The visual examination of histopathological images is a cornerstone of cancer diagnosis, requiring pathologists to analyze tissue sections across multiple magnifications to identify tumor cells and subtypes. However, existing attention-based Multiple Instance Learning (MIL) models for Whole Slide Image (WSI) analysis often neglect contextual and numerical features, resulting in limited interpretability and potential misclassifications. To address these limitations, we propose an enhanced MIL framework that integrates pre-contextual numerical information derived from semantic segmentation. Specifically, our approach combines visual features with nuclei-level numerical attributes, such as cell density and morphological diversity, extracted using advanced segmentation tools like Cellpose. These enriched features are then fed into a modified BufferMIL model for WSI classification. We evaluate our method on subtyping non-small cell lung cancer (TCGA-NSCLC) and detecting lymph node metastases (CAMELYON16 and CAMELYON17), achieving test AUCs of (INSERIRE I VALORI DOPO EVALUATION) respectively. 

\end{abstract}

\section{Introduction}
In recent years, computational pathology has emerged as a transformative tool for cancer research, leveraging Whole Slide Images (WSIs) to extract meaningful insights into tissue architecture and cellular composition. These large, high-resolution images are invaluable for diagnosing and prognosticating cancer, yet their sheer size, heterogeneity, and reliance on detailed annotations pose substantial challenges. Addressing these limitations requires innovative approaches capable of combining visual and numerical features from WSIs effectively \cite{litjens2017survey, campanella2019clinical}.

Multiple Instance Learning (MIL) has become a pivotal paradigm for WSI analysis. By treating a slide as a "bag" of smaller patches (instances), MIL allows slide-level predictions without the need for pixel-level annotations, streamlining the analysis pipeline \cite{ilse2018attention, campanella2019clinical}. Despite its utility, traditional MIL approaches often overlook critical contextual and numerical information that can enhance interpretability and predictive accuracy.

In this work, we introduce a novel pipeline that integrates cutting-edge tools and methodologies to overcome these limitations. We preprocess WSIs using the CLAM framework, ensuring the retention of essential visual features \cite{lu2021clam}. To extract nuclei-specific numerical features such as cell counts and density, we utilize Cellpose, a state-of-the-art segmentation algorithm \cite{stringer2021cellpose}. Simultaneously, we employ DINO, a self-supervised vision transformer, to generate embeddings representing the visual content of each patch \cite{caron2021emerging}. By concatenating these numerical and visual features, we construct a richer, more informative representation for each patch.

Our key innovation lies in adapting the BufferMIL framework to incorporate these enriched embeddings. By assigning greater importance to patches with high cell density or other critical numerical features, our model improves sensitivity to diagnostically relevant regions. This dual-feature approach enhances both interpretability and predictive performance, addressing long-standing challenges in WSI classification.

This paper is structured as follows: Section \ref{related} reviews key advancements in MIL and its applications in computational pathology. Section \ref{methods} describes our methodology, detailing preprocessing, feature extraction, and the enhancements made to BufferMIL. Section \ref{results} presents experimental results, discusses their implications, and outlines potential future directions. By combining numerical and visual features, our work seeks to advance computational pathology and provide deeper insights into the analysis of WSIs.

The source code is publicly available at \url{https://github.com/andrea-grandi/bio_project}.


\section{Related Work} \label{related}
Multiple Instance Learning (MIL) has revolutionized computational pathology by enabling efficient WSI classification without exhaustive pixel-level annotations. Despite its potential, traditional MIL approaches face limitations in capturing inter-instance relationships and integrating domain-specific knowledge. Recent advancements have sought to address these challenges.

BufferMIL \cite{10.1007/978-3-031-43153-1_1} is a notable framework that enhances MIL by incorporating explicit domain knowledge. Unlike traditional attention-based models that treat instances independently or rely on implicit spatial relationships, BufferMIL enables the integration of prior information, significantly improving interpretability and robustness. This aligns with the efforts of DeeMILIP, which demonstrated how probabilistic constraints can map domain entities to model components, enhancing generalization under weak supervision \cite{hajj2024}.

The Context-Aware MIL (CAMIL) model introduced neighbor-constrained attention mechanisms, leveraging spatial dependencies among WSI tiles to achieve superior performance in cancer subtyping and metastasis detection \cite{fourkioti2023camil}. Similarly, the Nuclei-Level Prior Knowledge Constrained MIL (NPKC-MIL) framework highlighted the benefits of combining handcrafted nuclei-level features with deep learning, demonstrating improvements in interpretability and classification accuracy for breast cancer WSIs \cite{WANG2024109826}.

Building on these advancements, our approach integrates nuclei-specific numerical features extracted via Cellpose into the BufferMIL framework. This integration enriches the bag representation with critical cellular attributes, such as density and morphological diversity, while leveraging high-dimensional visual embeddings from DINO. This combination bridges the gap between domain-specific insights and generalizable deep learning models, pushing the boundaries of WSI analysis.

In summary, the integration of prior knowledge into MIL frameworks, exemplified by BufferMIL, CAMIL, and NPKC-MIL, represents a paradigm shift. These models enhance both classification performance and interpretability, offering promising tools for computational pathology and personalized medicine.

\section{Methods} \label{methods}

\section{Experiments and Results} \label{results}

\section{Conclusions} \label{conclusions}

\bibliographystyle{unsrt}
\bibliography{references}



\end{document}