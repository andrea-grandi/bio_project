\documentclass[10pt,twocolumn]{article}

% Pacchetti di base
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\geometry{a4paper, left=1.5cm, right=1.5cm, top=2cm, bottom=2cm}

% Pacchetti aggiuntivi
\usepackage{graphicx} % Per inserire immagini
\usepackage{amsmath, amssymb} % Per simboli matematici
\usepackage{hyperref} % Per collegamenti ipertestuali
\usepackage{titlesec} % Per personalizzare i titoli
\usepackage{abstract} % Per formattare l'abstract
\usepackage{cite} 

% Impostazioni dei titoli delle sezioni
\titleformat{\section}{\Large\bfseries}{\thesection.}{1em}{}
\titleformat{\subsection}{\large\bfseries}{\thesubsection.}{1em}{}

% Intestazione e piede di pagina
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[C]{Multiple instance learning with pre-contextual knowledge - Andrea Grandi, Daniele Vellani}
\fancyfoot[C]{\thepage}

% Dati del documento
\title{\textbf{Multiple instance learning with pre-contextual knowledge}}
\author{Andrea Grandi, Daniele Vellani \\
\texttt{\{275074,196186\}@studenti.unimore.it}}
\date{Data}

\begin{document}

% Titolo e Autore
\maketitle

% Abstract
\begin{abstract}
\noindent 
The visual examination of histopathological images is a cornerstone of cancer diagnosis, requiring pathologists to analyze tissue sections across multiple magnifications to identify tumor cells and subtypes. However, existing attention-based Multiple Instance Learning (MIL) models for Whole Slide Image (WSI) analysis often neglect contextual and numerical features, resulting in limited interpretability and potential misclassifications. Furthermore, the original MIL formulation incorrectly assumes the patches of the same image to be independent, leading to a loss of spatial context as information flows through the network. Incorporating contextual knowledge into predictions is particularly important given the inclination for cancerous cells to form clusters and the presence of spatial indicators for tumors. To address these limitations, we propose an enhanced MIL framework that integrates pre-contextual numerical information derived from semantic segmentation. Specifically, our approach combines visual features with nuclei-level numerical attributes, such as cell density and morphological diversity, extracted using advanced segmentation tools like Cellpose. These enriched features are then fed into a modified BufferMIL model for WSI classification. We evaluate our method on subtyping non-small cell lung cancer (TCGA-NSCLC) and detecting lymph node metastases (CAMELYON16 and CAMELYON17), achieving test AUCs of (INSERIRE I VALORI DOPO EVALUATION) respectively. 

\end{abstract}

\section{Introduction}
In recent years, computational pathology has emerged as a transformative tool for cancer research, leveraging Whole Slide Images (WSIs) to extract meaningful insights into tissue architecture and cellular composition. These large, high-resolution images are invaluable for diagnosing and prognosticating cancer, yet their sheer size, heterogeneity, and reliance on detailed annotations pose substantial challenges. One computational challenge is the large size of WSIs, of the order of 100,000 $\times$ 100,000 pixels. Processing images of such size with deep neural network directly is not possible with the GPUs commonly available. Overcoming this problem, previous work proposes to tessellate each WSI into thousands of smaller images called tiles and global survival prediction per slide is obtained in two steps. The tiles are first embedded into a space of lower dimension using a pre-trained feature extractor model, and a MIL model is trained to predict survival from the set of tiles embeddings of a WSI (Herrera et al., 2016)\cite{8507932}. 

Multiple Instance Learning (MIL) has become a pivotal paradigm for WSI analysis. By treating a slide as a "bag" of smaller patches (instances), MIL allows slide-level predictions without the need for pixel-level annotations, streamlining the analysis pipeline (Ilse et al., 2018; Campanella et al., 2019)\cite{ilse2018attention, campanella2019clinical}. Despite its utility, traditional MIL approaches often overlook critical contextual and numerical information that can enhance interpretability and predictive accuracy.

One limitation of MIL is the assumption that tiles from the same WSI are independent (Ilse et al., 2018)\cite{ilse2018attention}. In particular, MIL models take into account only the visual knowledge comes from WSIs. In contrast, pathologists take into account also other aspects of WSIs in their analysis. Addressing these limitations requires innovative approaches capable of combining visual and numerical features from WSIs effectively (Litjens et al., 2017; Campanella et al., 2019) \cite{litjens2017survey, campanella2019clinical}.

In this work, we introduce a novel pipeline that integrates cutting-edge tools and methodologies to overcome these limitations. We preprocess WSIs using the CLAM framework (Lu et al., 2021) \cite{lu2021clam}, ensuring the retention of essential visual features. To extract nuclei-specific numerical features such as cell counts and density, we utilize Cellpose (Stringer et al., 2021) \cite{stringer2021cellpose}, a state-of-the-art segmentation algorithm. Simultaneously, we employ DINO (Caron et al., 2021) \cite{caron2021emerging}, a self-supervised vision transformer, to generate embeddings representing the visual content of each patch. By concatenating these numerical and visual features, we construct a richer, more informative representation for each patch.

Our key innovation lies in adapting the BufferMIL framework to incorporate these enriched embeddings, by assigning greater importance to patches with high cell density or other critical numerical features

%By assigning greater importance to patches with high cell density or other critical numerical features, our model improves sensitivity to diagnostically relevant regions. This dual-feature approach enhances both interpretability and predictive performance, addressing long-standing challenges in WSI classification.

This paper is structured as follows: Section \ref{related} reviews key advancements in MIL and its applications in computational pathology. Section \ref{methods} describes our methodology, detailing preprocessing, feature extraction, and the enhancements made to BufferMIL. Section \ref{results} presents experimental results, discusses their implications, and outlines potential future directions. By combining numerical and visual features, our work seeks to advance computational pathology and provide deeper insights into the analysis of WSIs.

The source code is publicly available at \url{https://github.com/andrea-grandi/bio_project}.

\section{Related Work} \label{related}
Multiple Instance Learning has revolutionized computational pathology by enabling efficient WSI classification without exhaustive pixel-level annotations. Under MIL formulation, the prediction of a WSI label can come either directly from the tile predictions (instance-based) (Campanella et al.,2019)\cite{campanella2019clinical}, or from a higher-level bag representation resulting from aggregation of the tile features (bag embedding-based) (Ilse et al., 2018)\cite{ilse2018attention}. The bag embedding-based approach has empirically demonstrated superior performance (Sharma et al., 2021)\cite{conf/midl/SharmaSEMSB21}. Most recent bag embedding-based approaches employ attention mechanisms, which assign an attention score to every tile reflecting its relative contribution to the collective WSI-level representation. Attention scores enable the automatic localization of sub-regions of high diagnostic value in addition to informing the WSI level label.

One of the first important work in this field was DS-MIL (Li et al., 2021)\cite{li2021dualstreammultipleinstancelearning}. This model utilizes a dual-stream framework, where patches are extracted from different magnifications (e.g., 5× and 20× in their study) of Whole Slide Images. These patches are processed separately for self-supervised contrastive learning. The embeddings obtained from patches at various resolutions are then concatenated to train the MIL aggregator, which assigns an importance or criticality score to each patch. The most critical patch is selected and compared to all others in a one-vs-all manner. This comparison uses a distance metric inspired by attention mechanisms, though it differs significantly by comparing two queries instead of the traditional key-query setup. Finally, the distances are aggregated to generate the final bag-level prediction.

Another work is BufferMIL (Bontempo et al, 2023)\cite{10.1007/978-3-031-43153-1_1}, which is a notable framework that enhances MIL by incorporating explicit domain knowledge for histopathological image analysis, particularly addressing challenges like class imbalance and covariate shift. In this approach, a buffer is maintained to store the most representative instances from each disease-positive slide in the training set. An attention mechanism then compares all instances against this buffer to identify the most critical ones within a given slide. This strategy ensures that the model focuses on the most informative instances, thereby improving its generalization performance. By leveraging a buffer to track critical instances and employing an attention mechanism for comparison, Buffer-MIL effectively mitigates issues related to class imbalance and covariate shift. This approach enhances the model's ability to focus on the most informative patches within WSIs, leading to more accurate and reliable predictions in histopathological image analysis.

Building upon the attention-based methodologies of frameworks like BufferMIL, Context-Aware MIL (CAMIL) (Fourkioti et al., 2024)\cite{fourkioti2023camil} extends the concept of informed instance selection by introducing neighbor-constrained attention mechanisms. CAMIL leverages spatial dependencies among WSI tiles to achieve superior performance in cancer subtyping and metastasis detection, showcasing the importance of spatial context in WSI analysis. Similarly, the Nuclei-Level Prior Knowledge Constrained MIL (NPKC-MIL) (Wang et al., 2024)\cite{WANG2024109826} highlights the value of combining handcrafted nuclei-level features with deep learning, demonstrating improvements in interpretability and classification accuracy for breast cancer WSIs.

%Building on these advancements, our approach integrates nuclei-specific numerical features extracted via Cellpose into the BufferMIL framework. This integration enriches the bag representation with critical cellular attributes, such as density and morphological diversity, while leveraging high-dimensional visual embeddings from DINO. This combination bridges the gap between domain-specific insights and generalizable deep learning models, pushing the boundaries of WSI analysis.

%In summary, the integration of prior knowledge into MIL frameworks, exemplified by BufferMIL, CAMIL, and NPKC-MIL, represents a paradigm shift. These models enhance both classification performance and interpretability, offering promising tools for computational pathology and personalized medicine.

\section{Methods} \label{methods}

\section{Experiments and Results} \label{results}

\section{Conclusions} \label{conclusions}

\bibliographystyle{unsrt}
\bibliography{references}

\end{document}